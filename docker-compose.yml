version: '3'

services:
  # New Backend Rust service
  oort-ml:
    build:
      context: ./ml
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
    volumes:
      - ./oort-ml-rust:/app/src  # For development only
    environment:
      - RUST_LOG=info
      - OLLAMA_URL=http://ollama:11434
    depends_on:
      - ollama


  # Frontend React service
  oort-fe-app:
    build:
      context: ./apps/frontend
      dockerfile: Dockerfile
    ports:
      - "3000:3000"
    volumes:
      - ./apps/frontend:/app
      - /app/node_modules
    environment:
      - NODE_ENV=development
      - REACT_APP_API_URL=http://localhost:8000
    depends_on:
      - oort-ml

  # Ollama service for embeddings and LLM
  ollama:
    image: ollama/ollama:latest
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    command: "serve & ollama pull cognitivetech/obook_summary"

volumes:
  ollama_data: